"""Observation term to generate footstep options as an isaaclab observation."""

import torch
import torch.nn.functional as F
from isaaclab.managers import (
    ObservationManager,
)

import src.constants as const
from src.gaitnet.actions.mpc_action import ManagerBasedEnv
from src.gaitnet.components.noisy_candidate_sampler import NoisyCandidateSampler
from src import get_logger

logger = get_logger()


_debug_footstep_cost_map = False
_debug_footstep_cost_map_all = False


class GaitNetObservationManager(ObservationManager):
    """Assumes the 4 footstep scanner values are at the end of the observation.

    Replaces the footstep scanner values with footstep options generated from the cost map.
    """

    def __init__(
        self,
        cfg: object,
        env: ManagerBasedEnv,
        footstep_option_generator: NoisyCandidateSampler,
        num_footstep_options: int,
    ):
        self.logged_update_history_warning = False
        self.footstep_option_generator = footstep_option_generator
        self.num_footstep_options = num_footstep_options
        super().__init__(cfg, env)
        self.footstep_options: torch.Tensor
        """Stores the latest footstep options generated by the manager (num_envs, options_per_leg*4, 4).
        Each option is represented as (leg_index, x_offset, y_offset, cost)."""
        self._footstep_actions: torch.Tensor
        self._overwrite_obs_dim()

    @property
    def footstep_actions(self) -> torch.Tensor:
        """Get the latest footstep actions with durations from the policy.

        Returns:
            torch.Tensor: Footstep actions of shape (num_envs, options_per_leg*4+1, 4)
                          Each action is represented as (leg_index, x_offset, y_offset, duration).
        """
        # If durations have been set by the policy, use them
        if hasattr(self, "_footstep_actions") and self._footstep_actions is not None:
            return self._footstep_actions

        # Otherwise, return options with default durations for initialization
        durations = torch.full(
            (self.footstep_options.shape[0], self.footstep_options.shape[1], 1),
            0.2,
            device=self.footstep_options.device,
        )
        _footstep_actions = self.footstep_options.clone()
        _footstep_actions[:, :, 3] = durations.squeeze(-1)
        return _footstep_actions

    def set_footstep_actions(
        self, action_indices: torch.Tensor, durations: torch.Tensor
    ) -> None:
        """Set the footstep actions for the selected action indices.

        This is called after action selection to attach durations to the selected options.

        Args:
            action_indices (torch.Tensor): Selected action indices of shape (num_envs,) or (num_envs, 1).
            durations (torch.Tensor): Footstep durations for selected actions, shape (num_envs,).
        """
        # Create full action tensor from options
        self._footstep_actions = self.footstep_options.clone()

        # Flatten action_indices if it has shape (num_envs, 1)
        if action_indices.dim() > 1:
            action_indices = action_indices.squeeze(-1)

        # Set durations for the selected options
        batch_size = action_indices.shape[0]
        batch_indices = torch.arange(batch_size, device=action_indices.device)

        # Update durations at the selected indices
        self._footstep_actions[batch_indices, action_indices, 3] = durations

    def _overwrite_obs_dim(self) -> None:
        """Overwrite the observation dimensions to account for footstep options."""
        self._group_obs_dim
        policy_obs_dim = self._group_obs_dim["policy"][0]
        # if this is a list throw an error
        if isinstance(policy_obs_dim, tuple):
            raise NotImplementedError(
                "FootstepObservationManager does not support list observation dimensions."
            )
        obs_dim: int = policy_obs_dim
        obs_dim -= const.footstep_scanner.total_robot_features

        # add in the footstep options
        # TODO: pull this from the footstep_controller action
        footstep_option_size = 8  # (leg_one_hot (5), dx, dy, cost)
        # +1 is for the NO_STEP option
        obs_dim += (
            self.num_footstep_options * const.robot.num_legs + 1
        ) * footstep_option_size
        self._group_obs_dim["policy"] = (obs_dim,)

    @staticmethod
    def footstep_options_to_one_hot(options: torch.Tensor) -> torch.Tensor:
        """Convert footstep options to one-hot encoding.

        Args:
            options (torch.Tensor): Footstep options of shape (num_envs, options_per_leg*4, 4)
                                    Each option is represented as (leg_index, x_offset, y_offset, cost).

        Returns:
            torch.Tensor: One-hot encoded footstep options of shape (num_envs, options_per_leg*4, embedding_dim)
                where the no-op option is the first index in the one-hot encoding.
        """
        num_envs, num_options, _ = options.shape
        embedding_dim = const.robot.num_legs + 1
        # +1 for no-step option to remap everything from -1-3 to 0-4
        one_hot = F.one_hot(options[:, :, 0].long() + 1, num_classes=embedding_dim)
        # replace leg index with one-hot encoding
        options_one_hot = torch.cat(
            [one_hot.float(), options[:, :, 1:]], dim=-1
        )  # (num_envs, num_options, 8)
        return options_one_hot

    def _modify_obs(self, obs: torch.Tensor) -> torch.Tensor:
        self.footstep_options = self.footstep_option_generator.get_footstep_options(obs)
        # (num_envs, options_per_leg*4, 4) where each option is (leg_index, x_offset, y_offset, cost)

        one_hot_options = self.footstep_options_to_one_hot(self.footstep_options)

        # Safety check: ensure no inf/nan values in observations
        if torch.any(torch.isinf(self.footstep_options)) or torch.any(
            torch.isnan(self.footstep_options)
        ):
            logger.error(
                "Found inf/nan in footstep options! This will cause training instability."
            )
            logger.error(
                f"Inf count: {torch.isinf(self.footstep_options).sum().item()}"
            )
            logger.error(
                f"NaN count: {torch.isnan(self.footstep_options).sum().item()}"
            )

        # replace the footstep scanner values at the end of the observation with the flattened footstep options
        obs = obs[:, : -const.footstep_scanner.total_robot_features]
        obs = torch.cat([obs, one_hot_options.flatten(start_dim=1)], dim=1)
        return obs

    def compute_group(
        self, group_name: str, update_history: bool = False
    ) -> torch.Tensor | dict[str, torch.Tensor]:
        obs = super().compute_group(group_name, update_history)
        # only modify the policy observation group
        if group_name != "policy":
            return obs

        if isinstance(obs, dict):
            raise NotImplementedError(
                "FootstepObservationManager does not support dict observations."
            )

        # the history will not be in the same shape as the observations
        if update_history:
            if not self.logged_update_history_warning:
                logger.warning(
                    "FootstepObservationManager history might not work as expected."
                )
                self.logged_update_history_warning = True

        obs = self._modify_obs(obs)
        return obs
